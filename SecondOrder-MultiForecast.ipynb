{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProcessingData:\n",
    "    \n",
    "    def __init__(self,filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            u = pickle._Unpickler(f)\n",
    "            u.encoding = 'latin1'\n",
    "            self.data = u.load()\n",
    "\n",
    "    def fix_data(self, interval):\n",
    "        \"\"\"Fixes up the data. Makes sure we count two stage as single stage actions, don't count float actions,\n",
    "        converts action duration and dt to floats, fill's nan's in action_duration and drops all datapoints which\n",
    "        don't have dt equal to interval.\n",
    "        :param data:\n",
    "        :param interval: float:minutes\"\"\"\n",
    "        def f(x):\n",
    "            if x == 0:\n",
    "                return 0\n",
    "            elif x == 2 or x == 5:\n",
    "                return 2\n",
    "            elif x ==1 or x == 3:\n",
    "                return 1\n",
    "\n",
    "        def h(x):\n",
    "            if x == 1:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        def c(x):\n",
    "            if x == 2:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        self.data[\"action\"] = self.data[\"action\"].map(f)\n",
    "        self.data['action_heating'] = self.data[\"action\"].map(h)\n",
    "        self.data['action_cooling'] = self.data['action'].map(c)\n",
    "\n",
    "        #print self.data.head()\n",
    "\n",
    "        return self.data, self.data[self.data[\"dt\"] == interval]\n",
    "    \n",
    "    def filter_data(self):\n",
    "        self.data = self.data.drop(['t_next', 'dt', 'action', 'previous_action', 'action_duration', \\\n",
    "                                    'zone_temperatureHVAC_Zone_Shelter_Corridor'], axis=1)\n",
    "        return self.data\n",
    "    \n",
    "    def drop_nan(self):\n",
    "        self.data = self.data.dropna()\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = ProcessingData(\"../Data/avenal-animal-shelter_training_data.pkl\")\n",
    "training_data = training.fix_data(5)\n",
    "training_data = training.filter_data()\n",
    "training_data = training.drop_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = ProcessingData(\"../Data/avenal-animal-shelter_test_data.pkl\")\n",
    "testing_data = testing.fix_data(5)\n",
    "testing_data = testing.filter_data()\n",
    "testing_data = testing.drop_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaling(data):\n",
    "    maxValues = []\n",
    "    scaled = np.empty([data.shape[0], data.shape[1]])\n",
    "    numSamples = data.shape[0]\n",
    "    numFeatures = data.shape[1]\n",
    "    dataValues = data.values\n",
    "    dataValues = dataValues.astype('float32')\n",
    "    for i in range(numFeatures):\n",
    "        maxNum = max(dataValues[:,i])\n",
    "        maxValues.append(maxNum)\n",
    "        for j in range(numSamples):\n",
    "            scaled[j,i] = dataValues[j,i]/maxNum\n",
    "    return scaled, maxValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "    data: Sequence of observations as a list or NumPy array.\n",
    "    n_in: Number of lag observations as input (X).\n",
    "    n_out: Number of observations as output (y).\n",
    "    dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "    Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var1(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.856761</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.641625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.641625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  \\\n",
       "2   0.856761   0.639420        0.0        0.0        0.0   0.856967   \n",
       "3   0.856967   0.639420        0.0        0.0        0.0   0.856967   \n",
       "4   0.856967   0.639621        0.0        0.0        0.0   0.856967   \n",
       "5   0.856967   0.640222        0.0        0.0        0.0   0.855734   \n",
       "6   0.855734   0.641024        0.0        0.0        0.0   0.856967   \n",
       "\n",
       "   var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)   var2(t)  var3(t)  \\\n",
       "2   0.639420        0.0        0.0        0.0  0.856967  0.639621      0.0   \n",
       "3   0.639621        0.0        0.0        0.0  0.856967  0.640222      0.0   \n",
       "4   0.640222        0.0        0.0        0.0  0.855734  0.641024      0.0   \n",
       "5   0.641024        0.0        0.0        0.0  0.856967  0.641625      0.0   \n",
       "6   0.641625        0.0        0.0        0.0  0.855734  0.641826      0.0   \n",
       "\n",
       "   var4(t)  var5(t)  var1(t+1)  \n",
       "2      0.0      0.0   0.856967  \n",
       "3      0.0      0.0   0.855734  \n",
       "4      0.0      0.0   0.856967  \n",
       "5      0.0      0.0   0.855734  \n",
       "6      0.0      0.0   0.856967  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled, train_scalers = scaling(training_data)\n",
    "train_reframed = series_to_supervised(train_scaled, 2, 2)\n",
    "train_reframed.drop(train_reframed.columns[-4:], axis=1, inplace=True)\n",
    "train_reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var1(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.856761</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.641625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  \\\n",
       "2   0.856761   0.639420        0.0        0.0        0.0   0.856967   \n",
       "3   0.856967   0.639420        0.0        0.0        0.0   0.856967   \n",
       "4   0.856967   0.639621        0.0        0.0        0.0   0.856967   \n",
       "5   0.856967   0.640222        0.0        0.0        0.0   0.855734   \n",
       "6   0.855734   0.641024        0.0        0.0        0.0   0.856967   \n",
       "\n",
       "   var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)  var1(t+1)  \n",
       "2   0.639420        0.0        0.0        0.0  0.856967   0.856967  \n",
       "3   0.639621        0.0        0.0        0.0  0.856967   0.855734  \n",
       "4   0.640222        0.0        0.0        0.0  0.855734   0.856967  \n",
       "5   0.641024        0.0        0.0        0.0  0.856967   0.855734  \n",
       "6   0.641625        0.0        0.0        0.0  0.855734   0.856967  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reframed.drop(train_reframed.columns[-5:-1], axis=1, inplace=True)\n",
    "train_reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var1(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.747789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.748107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.748107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.747249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  \\\n",
       "2   0.941785   0.747789        0.0        0.0        0.0   0.941785   \n",
       "3   0.941785   0.748107        0.0        0.0        0.0   0.944373   \n",
       "4   0.944373   0.748422        0.0        0.0        0.0   0.944373   \n",
       "5   0.944373   0.748731        0.0        0.0        0.0   0.944373   \n",
       "6   0.944373   0.749038        0.0        0.0        0.0   0.944373   \n",
       "\n",
       "   var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)   var2(t)  var3(t)  \\\n",
       "2   0.748107        0.0        0.0        0.0  0.944373  0.748422      0.0   \n",
       "3   0.748422        0.0        0.0        0.0  0.944373  0.748731      0.0   \n",
       "4   0.748731        0.0        0.0        0.0  0.944373  0.749038      0.0   \n",
       "5   0.749038        0.0        0.0        0.0  0.944373  0.748744      0.0   \n",
       "6   0.748744        0.0        0.0        0.0  0.944373  0.747249      0.0   \n",
       "\n",
       "   var4(t)  var5(t)  var1(t+1)  \n",
       "2      0.0      0.0   0.944373  \n",
       "3      0.0      0.0   0.944373  \n",
       "4      0.0      0.0   0.944373  \n",
       "5      0.0      0.0   0.944373  \n",
       "6      0.0      0.0   0.944373  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled, test_scalers = scaling(testing_data)\n",
    "test_reframed = series_to_supervised(test_scaled, 2, 2)\n",
    "test_reframed.drop(test_reframed.columns[-4:], axis=1, inplace=True)\n",
    "test_reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var1(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.747789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.748107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.748107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  \\\n",
       "2   0.941785   0.747789        0.0        0.0        0.0   0.941785   \n",
       "3   0.941785   0.748107        0.0        0.0        0.0   0.944373   \n",
       "4   0.944373   0.748422        0.0        0.0        0.0   0.944373   \n",
       "5   0.944373   0.748731        0.0        0.0        0.0   0.944373   \n",
       "6   0.944373   0.749038        0.0        0.0        0.0   0.944373   \n",
       "\n",
       "   var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)  var1(t+1)  \n",
       "2   0.748107        0.0        0.0        0.0  0.944373   0.944373  \n",
       "3   0.748422        0.0        0.0        0.0  0.944373   0.944373  \n",
       "4   0.748731        0.0        0.0        0.0  0.944373   0.944373  \n",
       "5   0.749038        0.0        0.0        0.0  0.944373   0.944373  \n",
       "6   0.748744        0.0        0.0        0.0  0.944373   0.944373  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reframed.drop(test_reframed.columns[-5:-1], axis=1, inplace=True)\n",
    "test_reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.85696673,  0.85696673],\n",
       "       [ 0.85696673,  0.85573369],\n",
       "       [ 0.85573369,  0.85696673],\n",
       "       ..., \n",
       "       [ 0.84956849,  0.85080147],\n",
       "       [ 0.85080147,  0.85573369],\n",
       "       [ 0.85573369,  0.85819978]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "train = train_reframed.values\n",
    "test = test_reframed.values\n",
    "train_X, train_y = train[:, :-2], train[:, -2:]\n",
    "test_X, test_y = test[:, :-2], test[:, -2:]\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53183, 2, 5) (53183, 2) (13387, 2, 5) (13387, 2)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 2, 5))\n",
    "test_X = test_X.reshape((test_X.shape[0], 2, 5))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53183 samples, validate on 13387 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.0582 - acc: 0.4280 - val_loss: 0.0187 - val_acc: 0.4042\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.0121 - acc: 0.4580 - val_loss: 0.0174 - val_acc: 0.3161\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.0115 - acc: 0.4594 - val_loss: 0.0223 - val_acc: 0.2734\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.0112 - acc: 0.4723 - val_loss: 0.0221 - val_acc: 0.2755\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.0109 - acc: 0.4737 - val_loss: 0.0214 - val_acc: 0.2766\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.0105 - acc: 0.4833 - val_loss: 0.0225 - val_acc: 0.2807\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.0102 - acc: 0.4866 - val_loss: 0.0205 - val_acc: 0.2782\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.0099 - acc: 0.4800 - val_loss: 0.0202 - val_acc: 0.2789\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.0094 - acc: 0.4902 - val_loss: 0.0183 - val_acc: 0.2789\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.0094 - acc: 0.4874 - val_loss: 0.0213 - val_acc: 0.2765\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.0090 - acc: 0.4929 - val_loss: 0.0196 - val_acc: 0.2753\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.0084 - acc: 0.4864 - val_loss: 0.0179 - val_acc: 0.2772\n",
      "Epoch 13/50\n",
      " - 3s - loss: 0.0082 - acc: 0.4968 - val_loss: 0.0158 - val_acc: 0.2765\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.0079 - acc: 0.4946 - val_loss: 0.0176 - val_acc: 0.2784\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.0073 - acc: 0.4902 - val_loss: 0.0145 - val_acc: 0.2791\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.0066 - acc: 0.4858 - val_loss: 0.0143 - val_acc: 0.3240\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.0066 - acc: 0.5014 - val_loss: 0.0127 - val_acc: 0.3210\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.0064 - acc: 0.5170 - val_loss: 0.0111 - val_acc: 0.3116\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.0057 - acc: 0.4870 - val_loss: 0.0130 - val_acc: 0.3524\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.0057 - acc: 0.5074 - val_loss: 0.0123 - val_acc: 0.3445\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.0054 - acc: 0.5144 - val_loss: 0.0119 - val_acc: 0.4108\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.0051 - acc: 0.5075 - val_loss: 0.0085 - val_acc: 0.6549\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.0047 - acc: 0.5040 - val_loss: 0.0103 - val_acc: 0.6964\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.0048 - acc: 0.4951 - val_loss: 0.0074 - val_acc: 0.2901\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.0043 - acc: 0.5127 - val_loss: 0.0073 - val_acc: 0.2815\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.0043 - acc: 0.5053 - val_loss: 0.0087 - val_acc: 0.6193\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.0043 - acc: 0.5229 - val_loss: 0.0075 - val_acc: 0.2898\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.0039 - acc: 0.5158 - val_loss: 0.0064 - val_acc: 0.2948\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.0036 - acc: 0.5224 - val_loss: 0.0087 - val_acc: 0.7167\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.0037 - acc: 0.5463 - val_loss: 0.0073 - val_acc: 0.5779\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.0037 - acc: 0.5295 - val_loss: 0.0068 - val_acc: 0.6961\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.0036 - acc: 0.5341 - val_loss: 0.0079 - val_acc: 0.6946\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.0035 - acc: 0.5382 - val_loss: 0.0082 - val_acc: 0.6981\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.0034 - acc: 0.5500 - val_loss: 0.0054 - val_acc: 0.6863\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.0032 - acc: 0.5437 - val_loss: 0.0085 - val_acc: 0.6953\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.0033 - acc: 0.5423 - val_loss: 0.0047 - val_acc: 0.7203\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.0031 - acc: 0.5553 - val_loss: 0.0047 - val_acc: 0.6984\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.0034 - acc: 0.5359 - val_loss: 0.0071 - val_acc: 0.6968\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.0033 - acc: 0.5396 - val_loss: 0.0089 - val_acc: 0.7015\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.0031 - acc: 0.5591 - val_loss: 0.0072 - val_acc: 0.6883\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.0032 - acc: 0.5535 - val_loss: 0.0070 - val_acc: 0.7012\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.0031 - acc: 0.5448 - val_loss: 0.0049 - val_acc: 0.6945\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.0029 - acc: 0.5687 - val_loss: 0.0058 - val_acc: 0.7291\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.0031 - acc: 0.5553 - val_loss: 0.0059 - val_acc: 0.7084\n",
      "Epoch 45/50\n",
      " - 3s - loss: 0.0032 - acc: 0.5531 - val_loss: 0.0076 - val_acc: 0.6918\n",
      "Epoch 46/50\n",
      " - 4s - loss: 0.0032 - acc: 0.5399 - val_loss: 0.0045 - val_acc: 0.6910\n",
      "Epoch 47/50\n",
      " - 3s - loss: 0.0030 - acc: 0.5584 - val_loss: 0.0049 - val_acc: 0.6928\n",
      "Epoch 48/50\n",
      " - 3s - loss: 0.0030 - acc: 0.5469 - val_loss: 0.0057 - val_acc: 0.6958\n",
      "Epoch 49/50\n",
      " - 3s - loss: 0.0030 - acc: 0.5675 - val_loss: 0.0055 - val_acc: 0.7022\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.0031 - acc: 0.5575 - val_loss: 0.0055 - val_acc: 0.6915\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VPW9//HXZ7bMZCUJYU1YVFDZ\nRAXUuhS1CLiBiojW1rqUblq7eFvtotVb79Vbf2pbtdYF17rihhUFEakbKouogCABWUJYQ1ayzfL9\n/fGdhJDMJBNICJz5PB+Pecxyzsx8D8b3OfNdxRiDUkqp5ODq6gIopZQ6cDT0lVIqiWjoK6VUEtHQ\nV0qpJKKhr5RSSURDXymlkoiGvlJKJRENfaWUSiIa+koplUQ8iewkIhOAvwJu4BFjzB3NtqcATwLH\nAyXAJcaY9dFtI4B/AplABBhtjKmN913du3c3AwYMaPeBKKVUMluyZMlOY0xeW/u1Gfoi4gbuB8YB\nRcAiEZlljFnZZLergVJjzBEiMg24E7hERDzA08D3jDGfi0guEGzt+wYMGMDixYvbKpZSSqkmRGRD\nIvslUr0zBig0xqwzxtQDzwGTmu0zCXgi+ngmcKaICHAW8IUx5nMAY0yJMSacSMGUUkp1vERCvy+w\nqcnzouhrMfcxxoSAciAXGAwYEZkjIktF5Df7X2SllFL7KpE6fYnxWvOpOePt4wFOAUYD1cA7IrLE\nGPPOXm8WmQ5MB+jXr18CRVJKKbUvEgn9IqCgyfN8oDjOPkXRevwsYFf09f8YY3YCiMhs4Dhgr9A3\nxjwEPAQwatQonetZKdVuwWCQoqIiamvj9hNxBL/fT35+Pl6vd5/en0joLwIGichAYDMwDbis2T6z\ngCuAhcAUYL4xxojIHOA3IpIK1APfBu7Zp5IqpVQrioqKyMjIYMCAAdgmRecxxlBSUkJRUREDBw7c\np89os04/Wkd/LTAH+Ap4wRizQkRuE5Hzo7s9CuSKSCHwK+DG6HtLgbuxJ45lwFJjzBv7VFKllGpF\nbW0tubm5jg18ABEhNzd3v37NJNRP3xgzG5jd7LWbmzyuBS6O896nsd02lVKqUzk58Bvs7zE6ZkTu\nlvIa7p67mnU7qrq6KEopddByTOjvrKznb/MLWbtjd1cXRSmVhMrKynjggQfa/b6zzz6bsrKyTihR\nbI4Jfb/XHkptUMd+KaUOvHihHw63nkmzZ8+mW7dunVWsFhKq0z8U+L1uAGo09JVSXeDGG29k7dq1\njBw5Eq/XS3p6Or1792bZsmWsXLmSyZMns2nTJmpra7n++uuZPn06sGfqmaqqKiZOnMgpp5zCRx99\nRN++fXnttdcIBAIdWk7HhH7AZ0Nfr/SVUre+voKVxRUd+plD+mRyy3lD426/4447WL58OcuWLWPB\nggWcc845LF++vLFr5YwZM8jJyaGmpobRo0dz0UUXkZubu9dnrFmzhmeffZaHH36YqVOn8tJLL3H5\n5Zd36HE4JvQbrvQ19JVSB4MxY8bs1Zf+b3/7G6+88goAmzZtYs2aNS1Cf+DAgYwcORKA448/nvXr\n13d4uZwT+h5bp19TH+nikiilulprV+QHSlpaWuPjBQsWMG/ePBYuXEhqaipjx46N2dc+JSWl8bHb\n7aampqbDy+WYhlyP24XP7aI2pFf6SqkDLyMjg8rKypjbysvLyc7OJjU1lVWrVvHxxx8f4NLt4Zgr\nfYAUr4uaeg19pdSBl5uby8knn8ywYcMIBAL07NmzcduECRN48MEHGTFiBEceeSQnnnhil5XTUaEf\n8Lq1Tl8p1WWeeeaZmK+npKTw5ptvxtzWUG/fvXt3li9f3vj6DTfc0OHlAwdV74BtzNXQV0qp+BwV\n+gGvW/vpK6VUKxwV+n6fm5qg9t5RSql4nBX6HpdW7yilVCscFfoBn9bpK6VUa5wV+l63dtlUSqlW\nOCr0/V63Ds5SSnWJfZ1aGeDee++lurq6g0sUm+NCX6dhUEp1hUMl9B03OKtO6/SVUl2g6dTK48aN\no0ePHrzwwgvU1dVxwQUXcOutt7J7926mTp1KUVER4XCYP/7xj2zbto3i4mJOP/10unfvzrvvvtup\n5XRU6Pu9Lu2nr5SCN2+ErV927Gf2Gg4T74i7uenUynPnzmXmzJl8+umnGGM4//zzee+999ixYwd9\n+vThjTfeAOycPFlZWdx99928++67dO/evWPLHIOjqncCXjehiCEY1ioepVTXmTt3LnPnzuXYY4/l\nuOOOY9WqVaxZs4bhw4czb948fvvb3/L++++TlZV1wMvmsCv9PXPqe92OOp8ppdqjlSvyA8EYw003\n3cSPfvSjFtuWLFnC7NmzuemmmzjrrLO4+eabD2jZHJWMfp8umaiU6hpNp1YeP348M2bMoKqqCoDN\nmzezfft2iouLSU1N5fLLL+eGG25g6dKlLd7b2Rx1pR9ouNLXHjxKqQOs6dTKEydO5LLLLuOkk04C\nID09naeffprCwkL+67/+C5fLhdfr5R//+AcA06dPZ+LEifTu3VsbctvD77U/XLSvvlKqKzSfWvn6\n66/f6/nhhx/O+PHjW7zvuuuu47rrruvUsjVwVPVOw5W+jspVSqnYnBn6WqevlFIxJRT6IjJBRFaL\nSKGI3Bhje4qIPB/d/omIDIi+PkBEakRkWfT2YMcWf28pTXrvKKWSjzGmq4vQ6fb3GNus0xcRN3A/\nMA4oAhaJyCxjzMomu10NlBpjjhCRacCdwCXRbWuNMSP3q5QJCmjoK5W0/H4/JSUl5ObmIiJdXZxO\nYYyhpKQEv9+/z5+RSEPuGKDQGLMOQESeAyYBTUN/EvCn6OOZwH3SBf/qjQ25upCKUkknPz+foqIi\nduzY0dVF6VR+v5/8/Px9fn8iod8X2NTkeRFwQrx9jDEhESkHcqPbBorIZ0AF8AdjzPvNv0BEpgPT\nAfr169euA2gqoP30lUpaXq+XgQMHdnUxDnqJ1OnHumJvXqkUb58tQD9jzLHAr4BnRCSzxY7GPGSM\nGWWMGZWXl5dAkWLT3jtKKdW6REK/CCho8jwfKI63j4h4gCxglzGmzhhTAmCMWQKsBQbvb6HjaZyG\nQfvpK6VUTImE/iJgkIgMFBEfMA2Y1WyfWcAV0cdTgPnGGCMiedGGYETkMGAQsK5jit5Siidap69X\n+kopFVObdfrROvprgTmAG5hhjFkhIrcBi40xs4BHgadEpBDYhT0xAJwG3CYiISAM/NgYs6szDgRA\nROySiVqnr5RSMSU0DYMxZjYwu9lrNzd5XAtcHON9LwEv7WcZ28XvdWnvHaWUisNRI3IBvdJXSqlW\nOC70/T4NfaWUisd5oe/RdXKVUioex4V+QK/0lVIqLseFvjbkKqVUfI4L/YDXrSNylVIqDseFvt/r\n1lk2lVIqDg19pZRKIo4Lfe2nr5RS8Tkv9LX3jlJKxeW40Pd7bO+dZFg2TSml2st5oR9dSKUupN02\nlVKqOceFvq6Tq5RS8Tku9BsWUtF6faWUaslxoa9LJiqlVHyOC32/N7p6lk7FoJRSLTgw9LV6Ryml\n4nFc6GtDrlJKxee40Pdr6CulVFyOC/2AT6t3lFIqHueFvvbeUUqpuBwX+ikNvXd0RK5SSrXguNBv\nbMjVK32llGrBcaGvDblKKRWf40Lf63bhcYk25CqlVAyOC33QhVSUUioeR4Z+itet0zAopVQMCYW+\niEwQkdUiUigiN8bYniIiz0e3fyIiA5pt7yciVSJyQ8cUu3UBn0vr9JVSKoY2Q19E3MD9wERgCHCp\niAxpttvVQKkx5gjgHuDOZtvvAd7c/+ImJuB1az99pZSKIZEr/TFAoTFmnTGmHngOmNRsn0nAE9HH\nM4EzRUQARGQysA5Y0TFFbpvf66Y2pKGvlFLNJRL6fYFNTZ4XRV+LuY8xJgSUA7kikgb8Fri1tS8Q\nkekislhEFu/YsSPRssfl1yt9pZSKKZHQlxivNV91PN4+twL3GGOqWvsCY8xDxphRxphReXl5CRSp\ndQGvW+v0lVIqBk8C+xQBBU2e5wPFcfYpEhEPkAXsAk4ApojI/wHdgIiI1Bpj7tvvkrfC73Vp7x2l\nlIohkdBfBAwSkYHAZmAacFmzfWYBVwALgSnAfGOMAU5t2EFE/gRUdXbgg/bTV0qpeNoMfWNMSESu\nBeYAbmCGMWaFiNwGLDbGzAIeBZ4SkULsFf60zix0WwI+rd5RSqlYErnSxxgzG5jd7LWbmzyuBS5u\n4zP+tA/l2ycpHr3SV0qpWBw5Ilev9JVSKjZHhr7f4yYYNoTC2pirlFJNOTL0Az5dSEUppWJxZujr\nkolKKRWTI0M/RRdSUUqpmBwZ+gENfaWUisnRoa/dNpVSam+ODP096+RqQ65SSjXlyNBv6L2jV/pK\nKbU3R4a+X+v0lVIqJg19pZRKIo4Mfe2nr5RSsTky9PVKXymlYnNk6O/psqm9d5RSqilHhn6KR3vv\nKKVULI4MfZdLSPG4qNPQV0qpvTgy9MHOqa9X+koptTfnhr7Xrb13lFKqGceGvt/r1vn0lVKqGUeH\nvl7pK6XU3hwc+i7qQhr6SinVlGNDX+v0lVKqJWeHvvbeUUqpvTg29P1et07DoJRSzTg89LX3jlJK\nNeXY0A/4XFq9o5RSzSQU+iIyQURWi0ihiNwYY3uKiDwf3f6JiAyIvj5GRJZFb5+LyAUdW/z4/B6t\n3lFKqebaDH0RcQP3AxOBIcClIjKk2W5XA6XGmCOAe4A7o68vB0YZY0YCE4B/ioinowrfmoZpGIwx\nB+LrlFLqkJDIlf4YoNAYs84YUw88B0xqts8k4Ino45nAmSIixphqY0wo+rofOGAJ7Pe6MQbqdFSu\nUko1SiT0+wKbmjwvir4Wc59oyJcDuQAicoKIrAC+BH7c5CTQqRoWUqnTxlyllGqUSOhLjNeaX7HH\n3ccY84kxZigwGrhJRPwtvkBkuogsFpHFO3bsSKBIbduzkIrW6yulVINEQr8IKGjyPB8ojrdPtM4+\nC9jVdAdjzFfAbmBY8y8wxjxkjBlljBmVl5eXeOlb4ffaQ9PGXKWU2iOR0F8EDBKRgSLiA6YBs5rt\nMwu4Ivp4CjDfGGOi7/EAiEh/4EhgfYeUvA16pa+UUi212ZPGGBMSkWuBOYAbmGGMWSEitwGLjTGz\ngEeBp0SkEHuFPy369lOAG0UkCESAnxpjdnbGgTTn92noK6VUcwl1nzTGzAZmN3vt5iaPa4GLY7zv\nKeCp/SzjPvF7bOhr9Y5SSu3h4BG5GvpKKdWcc0O/oU6/XrtsKqVUA8eGvvbeUUqplhwb+tp7Ryml\nWnJs6Pu1Tl8ppVpwbuhr7x2llGrBsaHvdQtul2j1jlJKNeHY0BcR/B6Xrp6llFJNODb0Yc+c+kop\npSxHh77f66a2XkNfKaUaOD/0Qxr6SinVwNGhH/C6qdErfaWUauT80Nc6faWUauTo0E/xau8dpZRq\nytGhH/C6dXCWUko14ezQ92noK6VUU44Ofb9H6/SVUqopR4d+wKe9d5RSqilHh36K10VtSBtylVKq\ngaNDP+B1Ux+KEI6Yri6KUkodFBwf+qDTKyulVANHh76/rdAv3wybPoWqHWD249fAls/h5R/B1i/3\n/TOUUuoA8HR1ATpTq0smGgNPXQA7V9vnvgzIGQA5h0H2QOg9Ao48B7z++F9QVwnv/i988g8wEVj3\nLlz9NmT37/iDUUqpDuDo0G91ycQtn9vAP/Fn0K0f7Fpnb9tWwKrZEAlCai4cezkcfyXkDNz7/V/9\nG978DVRsttuPuRSeuRievgiungupOQfgCJVSqn2cHfoeW3sVcyqGL18ElxdOu6FlQIdDsP49WPQo\nfPR3+PBvcMR3YPQ10OMoeOsmWD0beg6Dix+HgjH2fZc+B09OhmenwfdfA2+gcw9QKaXaydGhH/DF\nqd6JhGH5SzBoXOwrcrcHDj/D3so3w9InYMnj8Owldrs3Fcb9N5z4E3B797yv/7fgwofgxR/AS9fA\n1CfB5e6Yg6nfDStegWEX6clEKbXPHN2QG7f3zoaPoHILDJ/S9odk9YXTfwe/XGGv6k/+BfzsEzj5\n53sHfoOhk2HCHbAqWv2zPw3ETb1zG7z2M3h6im1LUEqpfZBQ6IvIBBFZLSKFInJjjO0pIvJ8dPsn\nIjIg+vo4EVkiIl9G78/o2OK3rqH3TotRuV++CN40GDwx8Q9ze2HoBTDuVtsG0JoTfwzf+jksegQ+\nuKedpY5h20r49GEoOAE2LoQnzofqXfv/uUqppNNm9Y6IuIH7gXFAEbBIRGYZY1Y22e1qoNQYc4SI\nTAPuBC4BdgLnGWOKRWQYMAfo29EHEY8/Vu+dUD2sfA2OPhd8qZ335d+5FSqK4Z1bbVfOXsMg7yh7\nyx6QeLWPMfDWbyElw7YZbPoEXrgCHj8HvvcKZPTqvGNQSjlOInX6Y4BCY8w6ABF5DpgENA39ScCf\noo9nAveJiBhjPmuyzwrALyIpxpi6/S55Avxe+0OmrmlD7tp3oLYMhl/cuV/ucsHkB2yXz7ULYMXL\ne7a5U6D7IFuGk68Hkfif89Us+OY9OPsu2/5w5ET47ovw7KUwY4JtMNYuokqpBCUS+n2BTU2eFwEn\nxNvHGBMSkXIgF3ul3+Ai4LMDFfgQp5/+ly9CIAcOG9v5BfCkwKT77ePaCtj5NexYZW+bFsG8W+y2\nU34R+/311TDn97aX0PFX7nn9sG/DFbNs99DHJsL3XoW8wZ17LEopR0gk9GNdhjZvnWx1HxEZiq3y\nOSvmF4hMB6YD9OvXRn15O7TovVNXZfvgj7wsdiNsZ/JnQv4oewOIRODla2zwp+XBsd9t+Z4P/wrl\nm+CCB22PoqbyR8EP3rADzB6bCN9/FXoN7/zjUEod0hJpyC0CCpo8zweK4+0jIh4gC9gVfZ4PvAJ8\n3xizNtYXGGMeMsaMMsaMysvLa98RtMLvadZ7Z/VsCNV0ftVOIlwumPwgHHY6zLoOVr+59/bSDfDh\nvTD0QhhwSuzP6DUMrnrL/qJ4chJs/6rzy62UOqQlEvqLgEEiMlBEfMA0YFazfWYBV0QfTwHmG2OM\niHQD3gBuMsZ82FGFTpTLJfg8rj1X+l++CFkFthfMwcDjg0uegt7H2L79Gxbu2Tb3DyAuOOu/W/+M\n3MPhitftQLMnzoedazq1yEqpQ1uboW+MCQHXYnvefAW8YIxZISK3icj50d0eBXJFpBD4FdDQrfNa\n4AjgjyKyLHrr0eFHAXbA1cIHIFiz18sBr5va+jDs3gmF79jBTa6DaHhCSoZtmM3Kt4O/tq2AdQts\nA+6pv7Kvt6Uh+AGeOA9KYv6gUkopxHTU4KEOMmrUKLN48eL2v3HdAlvF0Ws4TH2qca6cE/5nHmMH\n9+DO/p/CG7+GH39oq0UONmUb4dFok4cvHcL18LNPW5/wrbltK+GJc8ETgCtna68epZKIiCwxxoxq\na7+D6JJ3Px02Fi57Aco2wT+/bRtssVf6NcEwfDkT8o6GnkO7tJhxdesHl78MwWooWQMT/rd9gQ/Q\nc4jtwllfZcO/vKhzyqqUOmQ5J/QBBo+HH71nr/KfuxTevoVUD6TWFNuRrMOntN4nvqv1HGKraSb+\nBY48e98+o9dw25OnphweP9cOEFNKqShnhT7YKo2r5th+7R/ey53VN3ParpfstmEXdW3ZEtH7GDhh\n+v6dnPocC5e/ZNsx/nWx7aqaiNpyKNqHqjWl1CHDeaEPtlrkvHth8oMMDq3m7KqXIH90yznxnaxg\nNEx9AravhJen23EBraktt43Aj5xpVxNTSjmSM0O/wchL+XOvv7PcM9ROd5BsjjjTzvi5+g2Yf1v8\n/ep3w7+m2obgQLbtLnqQNfArpTqGs0MfKEk/gl+k/i8cfV5XF6VrjJluq7o+uAeWPdtye7AWnvsu\nFH0KFz0C3/mTndTtq9cPdEmVUgeA40Pf73W3nFo5mYjA2X+BgafB6z+HjZ/s2RYOwsyr7Nq+k+63\nawGMvNz2cpp3i52RVCnlKEkR+nWhJA59sPMMXfyEHej13GV2TEAkDK/+xFb9nH2XnY8I7Bw/426z\n6wUveaxry62U6nCOD/1Asl/pN0jNgUuft1f3z0yzV/1fvghn3gJjfrj3voPG2V8GC+6wDbxKKcdI\njtAPhjnYRh53ibzBcPFjdmrnz56GU39tp3poTsSuAVyzC96/+8CXUynVaRy9MDrYhVQiBoJhg89z\nEA/MOlCOONM22JYXwbeui79fn5EwYhp8/A8YfQ10K4i/r1LqkOH4K/2YSyYmu2EX2oXd2xoAdsYf\n7P38P3d+mZRSB0TShH6dhn77dSuAE38CXzwHxcu6ujRKqQ7g+NCPuWSiStypv7LLS879g+3Tr5Q6\npDm+Tr/FkomqffxZMPZGePM3cHtPewLI6A2ZvSGjF2Tm26Ueu3XcMpdKqc7j+ND3e+2PmdpgG3PP\nqPhG/xDSe8DOQqgshsqtdvbOrcuhahssnmEXgukzsqtLqpRqQxKEfvRKX/vq7zuXC4ZeEHvbjtXw\n9EXw+Dkw9UnbO0gpddBKmjr9Wq3e6Rx5R8LVb0P2AHhmKnz+fFeXSCnVCseHvl9Dv/Nl9rbLM/Y7\nCV6ZDh/cq7N0KnWQcnzoa++dA8SfZRduGTbFTtb25m/t/D6JWjkL/nkavHeXbTNQSnUKx9fpN/Te\n0YbcA8CTAhc+bHv1LLwPdu+ACx+yE761Zv0H8NLVkJIJ8/8bFvwvHDnRTgl92Om2TUEp1SEcH/p+\nj17pH1AuF4y/3fb2eftmCNfDlBn2hBDLthXw7GWQPRCueguqd8HSx2HZM3ZO/2794bjv25NA3tF6\nAlBqPzk/9H02JNbtqKI2GG6s41ed7OTrwZsKs2+A5y+HqU/ZZSybKi+Cp6eAL9VWDaXm2NtZf4Yz\n/mhDf8nj9up//n9Dai4MOAUGnGpnAe0++OBe6F6pg5AcbLNPjho1yixe3HGLcxtjGHvXAjaUVJOe\n4uH0o3owcVgvxh6ZR6rP8ee8rrfkcXj9F3DYt2HaszbgAWpKYcZEqNgMV74JvYbF/4yyTfDNe7D+\nffjmfagosq+n94Tz/mp/BSiV5ERkiTFmVJv7OT30AepDET5au5O3lm9l7spt7Npdj9/r4tuD8zhl\nUB5DemcwuGcGGf426p7Vvln2LLz2U9u757LnweWFpy+0C7Bf/pI9ISTKGCj9xob/wvsgWAPXLQWP\nr/PKr9QhQEM/jlA4wqL1pby1fAtvrdjKtoq6xm0FOQGO6pXJUb0yOLKXPREMyE3D59F65P22/CV4\n6YfQ93hb37/q33DRozB8yr5/ZuE8OzDsnLth9NUdV1alDkEa+gkwxlBcXsuqLRWs2lrJV9H7dTuq\niET/WTwuYWD3NAb3zOCIHukc2SuD4X2zyM8OIFqf3D5fvQ4vXgmRIJx1O3zr2v37PGNgxnjbNnDd\n0pZtBkolkQ4NfRGZAPwVcAOPGGPuaLY9BXgSOB4oAS4xxqwXkVxgJjAaeNwY0+b/5Qcy9OOpDYYp\n3F7Fmu2VrNlWxdfbqijcXsmGXdWNY45y0nwM75vFMflZjMjvxoiCLHpkaOi06Zv3YddaOP4HHfN5\n6xbAk5Ng4l/ghOkd85lKHYI6LPRFxA18DYwDioBFwKXGmJVN9vkpMMIY82MRmQZcYIy5RETSgGOB\nYcCwQyX046kNhvl6WyVfFJXzRVEZXxSV8/W2ysZfBQU5AY7vl83x/bM5vn8OR/bKwO3SXwOdyhg7\n70/JWrh+GXgDre8fDtnF35VymERDP5G//jFAoTFmXfSDnwMmASub7DMJ+FP08UzgPhERY8xu4AMR\nOaI9hT9Y+b1ue1Wf3w3oD0B1fYgVxRV8vqmMJRtK+XBtCa8uKwYgPcXDsf26MahHBvnZAfKzA/TN\nDpCfnUpWQBuNO4QInP47G/yLH4OTfhp7v3AIXvkRFH0KP3ofAt0ObDmVOkgkEvp9gU1NnhcBJ8Tb\nxxgTEpFyIBfY2RGFPJil+jyMHpDD6AE5XHOqbScoKq1hyYZSFm/YxdINZSxev7HF4LAMv4eje2Vy\n+lE9+M7RPTiiR7q2EeyrAafYfvsf3GOrjRq6hTaIROC1n8HymYDY5R/PuasrSqpUl0sk9GMlUfM6\noUT2if8FItOB6QD9+h3ai3GICAU5qRTkpDL52L6APRGUVgcpKq2mqLSGzaU1bCqtZsmGUu58axV3\nvrWKgpwAZx7VkzOO6sGYgTmkeFx6EmiPsb+DxybA4kf3XvDdGJj9a7vk4+l/sFNDfPqQXfilz7Fd\nV16lukgioV8EFDR5ng8Ux9mnSEQ8QBawK9FCGGMeAh4CW6ef6PsOFSJCTpqPnDRftGpojy3lNby7\nagfzV23juUUbefyj9Y3bPC7B63bhcdv7gNfN0b0zGN7XNhyP6JtFbnqc6Q2STf+T4PAz7Ayfx18J\nKek28Of+wS7ycsov4bQboK4CVrwC//4VXDMPXDpCWyWXREJ/ETBIRAYCm4FpwGXN9pkFXAEsBKYA\n883B1hf0INU7K8BlJ/TjshP6URsMs3BtCSuKy6kPG0LhCKGIoT4UIRSJUFETYkVxOe+s2t7Yi6hv\ntwDHFGQx9sgejB/Si6zUJG4rGPs7ePQ7sOhhG/L/udMO4BozHc68xdb/+7Ng/P/Ay9fY0cLav79r\nGAPbv7LrMeiJ94BKtMvm2cC92C6bM4wxt4vIbcBiY8wsEfEDT2F76uwCpjVp+F0PZAI+oAw4q2nP\nn+YO5t47B4vK2iDLN1fYHkSby1m6oZQt5bV43cKpg/I4d0RvvjOkJ5nJOML4XxdD0SI44cd2ts6R\nl8P5f997ojZj4InzYOsXcO0SSM9r//esfdeuC5x7+P6Vt67K/vIYdiH40vbvsw4l7/8/eOc2GDIZ\nLnqk7ZlYVZt0cFYSMcbweVE5b3xRzBtfbKG4vBaf28W3j8xjzIAcCnJsj6GC7FQyAx5ntxVsXgIP\nn2EfD73QBkqsK8kdX8M/vmVHBF/wYOKfH6qDOb+DRY+AJwDjboPR1+zb7J/GwEvX2AbmXsPh0ucg\nK7/9n9PRImGY83v7b5PfZoa03+IZ8O9fQq8R9sR79Pl2JlYN/v2ioZ+kIhHDZ5vKeOOLLby5fAtb\nymv32p6R4iE/J5WB3VMZ2ie1ThNxAAAR+UlEQVSLoX0yGdY3i+5Oaht449dQXw3n/631IHnnNnvF\n+YM3bA+gtpQXwQtXwObFcOJPYecaKHzbzvk/+QHI7NO+ci59EmZdZxee+XqOHWNw6bMdE7R1lVC8\nDIqX2hNhsNYGa0p62+9d8gS8/nMoOBGunrP/ZWlq+csw8yoYdBZM+xd8+jDMuQmOOhemPKZzKO0H\nDX0FQHl1kE2l1RSVVrNpV429L62hcHsVG3dVN+7XK9PP0D6ZHFPQjTOP7sGQ3pnO/kUA9sRw/wm2\ni+ePP2j9BLH2XbvQS6jeBvyQ8+2V+uIZtrHY7YNz74ZhFyX23dtW2l8k/U6Ay1+GnV/DM5fYVcMm\nP7BvcxKtmQcrXrYhv2M1jR3ouvWDso22V9NZf279M2or4O/H2X+b4G64eh4UjG5/WWIpnAfPTLMn\ntctf3tO19uMH4a3fwpHnwMWPa/DvIw191abymiAriytYUVzOiuIKlm8up3BHFcZAfnaA8UN7MX5o\nL47vn+3ckcWr34Rnp9lqmpOvb7k9EoEP/h/Mvx3yjoJLnobuzcYalqyNDvxaZK/az7kLAtnxv7N+\ntw386l3wkw/tBHQAu0vs2gMbP4LTfgNjb0qs2qh0Pbx1E6yebdcc6DvKTmzX9zjocxyk5dpfFJ/9\nC370H1uVFM/bt8CH98IV/4bnvwuHjYWpT7ZdhrZs+tROl5FzOPzg3y0Hx336sF17YfBEmPpE/EV3\nOtv2r+zKb6399ztIaeirfbKzqo55K7cxZ8VWPiwsoT4coXu6j3FDenLJ6H6MLHDgSNZnL4U1b0N2\nf/Cl21tKum1YrdhiQ3j4xXbu/niNreGQHRz2nzsgtbsN/qPPi73vaz+zAfz9V22oNhWqt/Xdy562\ndd3jb7dX6rEEa+DDv9rvFTd8+ze22inWlXL1LrhvNOQMhKvmxj6ZlK63+wy7yLZzzPuT/fzrlkDO\nYbHLkIhtK+GxiXaBnKvm7DnJNbfoEVs1N2i8bYvxZ+77d+6L5S/bNpaCMXaNh0Psl66GvtpvlbVB\nFqzewZwVW5m/ajvV9WFG5GfxvRP7c94xfZyzClnlNnj/Ljtwq363vdVV2vtIEE66Dsb8MLEQKF4G\ns66FrV/a0D/7Lnvl2ODz5+GV6fZK/ozfx/4MY2xX07l/BAxk5kP/b9mxCP1PtiuGff2WXXy+bINt\nsD7rz5DVt/Wyff6c/UVy7j0w6qqW21/4vj35XbfEtk9UbIF7h8OoK+Hsv7R97LGUbYRHxtl/u6vm\n2BNraxoaeQEyettfBrmHRe8Pt8efmrNvZWnNFy/a/y7pvaCy2FYzDb2g47+nE2noqw5VWRvklc82\n8+TCDRRuryI71cvU0QVcfkJ/CnJS2/6AZBIO2tBecIetpjjrz3Ds92w10D9Pgz4j4fuz2p74bcfX\ndhbRjR/Bho+gapt9PSXTDjLLO8qG8cDTEivXXl1VF+99xb3hI3s1fvrv7S+GBq/8BFa+Cr9c0f6w\nDQdhxgTb4H31HOhxdGLvW/8hbFwIu9bZf7OSQqiOzuiSVQDXvAMZPdtXltY0LPLT/2SY9oz9d6it\ngGsXHVLTdWvoq05hjGHh2hKeXLiBuSu3EjF2Yjmfx4U3OnLY53Hhc7vIDHjpmemnZ0YKPTP99Mi0\n94fnpZOX4aDeQvGUrIVZP4cNH9h1fWtKoaLY1uO3t6ePMTYENy6ETZ9AjyG2q2h7uznuXGO7qg6Z\nDBc9bF+LRODhsbB7pz0ZNJ27aNsKu/8Zf7Qjmttj3p9s1VNHXDXXlsOmRfDC96DnULji9bZnVE3E\n0qdse0fT5Ty/ec+eHM+8GU799f5/xwGioa86XXFZDa98tpmSqnqC4QjBcIT6UIT66H1ZTZDtFbVs\nq6jba8I5l8C3B+cxdVQBZx7d09krk0Ui8NmTtqqmrgIuexEGn9W1ZZp/O7z3f/C9V+Hw0237wms/\nhQsfgREXt9z/qQttddUvlyfewLr2XXjqAjju+7brbEdZOcsG/7CL7Mpr+1Pv3lCVdMR3bAN905PI\nc9+1x/DzpXtXzx3ENPTVQcMYQ2VdiO0VdWyrqOXjdSW8uLiIrRW15KT5uODYvkwdVcCRvTK6uqid\np3Ir7PrG1st3tWAtPHAiiMvOP/TASXZQ2DXzYofo2nfhqclw/n1w3Pfa/vyqHfDgyeDvBtMXtJz1\ndH+9fze8c6vt3TT2xtb3NcYOqAtW21tDV9R1/4F5t9hG46lPtqzG2bUO7hsDIy6Byfd3bPk7iYa+\nOqiFI4b31+zghcWbeHvlNoJhw+F5aaT7vbjETtvqEsElgtslDOie1rh28VG9MuiWqn2598va+fZK\nPHugXWi+tf74xsCDp9pG7Z9+3PrVdSQCz1xsV0ib/q6tiuloxsCrP4HPn42/znLpBts4//nzEK5r\nuR2i4wIei//rZe4f4aO/2+No74ysmxbBV7MgJQPS8iC9Z/SWB2k9bLWcidjRzyay5+Zy7/N0HBr6\n6pCxa3c9r362mQ8KdxKKGIwxGAMGQyQCdaEw63bupqw62PienpkpHNUrkyF9MhnWJ4thfTPpl5Pq\n/AFlHWnm1XYKiGFTYMqjre/b0OvouzNh0Lj4+310H8z9ve21NOaHHVvepkJ1tt//5qVw5ew9o5jL\nNsJ7d8Gyf9lurMdcAtkDwJtmq298aeBNtRPvFZzQemN6bTn87TjbW+rK2W1XJYVD8NVrsPABO2rb\n5YFIqH3HNfRCeyLaBxr6ylGMMWyrqGPV1gpWb61k9dZKVm6poHB7FaHoepUZKR57EuhrTwLD+2Yx\nsHu6cweW7a+qHfDeX+yMpJm9W983HIR7R9iBaVe8Hnuf4s9s98zB420deWefgHeXwMOn2/EKU5+0\nayZ89i/7vcddAaf+qv0N5s0tfgz+/Qu4+AkYOjn2PjVlsPQJ+OQhqCiyv55O/AmMvMyO1N69A6q2\nR2/bYPd2+4tIXHa8hDTc3NB9kP332wca+iop1IXCrNlWxfLN5SyPjiz+aksFtcEIAKk+N0N6N5wI\nsuiXk0owHKEuFKYuGKEuZB8LwrH9uukKZq358K/w9s0w/T/Q+5ho1UTYXs3W74YZ4+3gsh+/3zl9\n6WPZvgoeHWcbyV1e23B86q86buK6SNh2s62rgJ9Fu3DW77YnuE2f2lHY6/5j2wkGnGoHxw0e3yXT\nRWvoq6QVCkdYt3M3XxaV8+XmcpZvLmfllgqq68Ntvrd7uo8TDsvlxMNyOemwXA7PS9OTQIPacrh7\nKNRXxt4uLjt5Xf9vHdhybfjIDlYb/UPoVtD2/u217j/w5Pl2PERNme3GaqJ/S7lH2Mn6Rl0NvUd0\n/He3g4a+Uk2EI4ZvdlZRXFZLisdFitdt7z0u/F43tcEwi9eX8vG6EhauK2mcnTQ3zUdmdBH7xuiP\nPvC5XaT63KT6PAR87uhjN72zAowakM2xBdkEfA4Ztdxgzdt2nIC47dWsy73nce9jEh8odqiZeZWd\nCbXvcZA/xk7VkD/6wP2iSYCGvlL7yBjDxl3VfLyuhCUbSqkNRhoXfG74/8UA9aEINfVhqutDVNeH\nqQmGqa4Ps7OqDmPscpfD+mYxZmAOowfkMLKgG93TffrL4VBlzEE9H4+GvlJdpLw6yNKNpXy6fheL\n1+/i803l1If3tDEUZKc2LmyTnx2gV5afumCEqroQVXUhKmqDVNWG2F0XwiWCL/qLxNdwc7vxe10E\nfG78XjcB75771BQ3mX4vmQEPmX6vc+ZHUm1KNPQTWSNXKdUOWaleTj+qB6cfZee2qQ2G+aLIti1s\narKuwcK1JeyO0c7g87jISPGQluIhYsxeo5ztesmJX6j5PC57EvDvqYIK+Dykeu3jtBQPvbL85Gfv\nOQnlpafg2s8eT+GIYUt5DRtLqtleWYfbtffJy1atuemRmUL3tP3/PpU4DX2lOpnf62bMwBzGDNy7\n/tcYQ1l1kG2VtQS8btJTPKT7PaR4Wr86D0cMdaEwNdEqpdpghNqgfVxVF6KiJkhFbcN9kIqaEJW1\nwWhVVJjymiBby2uorg9TWRuivCa41+f73C76dPPjcbuoD0Uap9ioiz72uV10S/WRneolK3rfLeDF\nABtKqtm4yy7aEwwndnLyuV30yvLTO8tPn24Bemf58biEupA9rqb3xoDfa9thGtpjUrxu0lPcdp6n\n6K1Xpn+v9pRwxFBeE2TX7npKq+sp3V3fWCVX0+zenlgjhMKGUMQQDEcIRww+j4u89BS6Z6TsdZ+T\n5tvrl5jHJXtV4YUjpvG/T019mNpgmGDYEDGGcMR+R8QYQmFDbrqPwT07d2S6hr5SXUREyE7zkZ3W\nvtHFbpeQ6vOQ6uuY/32r60NsLq2hqLSGojL7K6S4rJZIxOB1S3QyPVfjZHr1oQil1fWUVQcpq65n\nQ8luSnfXY4B+Oakc3TuD8UN70T83lX45qfTM9Df+YqmL/lqpC9nw215Zx+ayGraU1bKlvIZPv9nF\n1opawhGD32t/DTS9BxpPcg0ngrpQJOZxZfg95KT5qKgJUlYTpK2abJdAwOu2we124XUJbrfgdbnw\nuIWaYJidlfV7zSMV73N8Hhdel8sebzh2+WI5d0Rv7rvsuIT33xca+koluVSfh0E9MxjUyVeYiYpE\nDCIk3OAdidi5nXZU1rK13M7vtLWilu0VtZRWB8kKeMlO85GTGr1P85Gd6iMtxUOgoU3EZ2eGTeQ7\nd9eF2FFZx46qOnZW1rGrur6x6q3xxBb9dZTisZ8f8LkIRH+V+L1ufG47xYin4d7lwuWCvAOwVrWG\nvlLqoNLe+n2XS8gKeMkKeDmiR+efuNKi7S0Duu/bHDldzcFz2iqllGpOQ18ppZKIhr5SSiURDX2l\nlEoiGvpKKZVENPSVUiqJaOgrpVQS0dBXSqkkctDNsikiO4AN+/ER3YGdHVScQ4ked3LR404uiRx3\nf2NMXlsfdNCF/v4SkcWJTC/qNHrcyUWPO7l05HFr9Y5SSiURDX2llEoiTgz9h7q6AF1Ejzu56HEn\nlw47bsfV6SullIrPiVf6Siml4nBM6IvIBBFZLSKFInJjV5ens4jIDBHZLiLLm7yWIyJvi8ia6H12\nV5axM4hIgYi8KyJficgKEbk++rqjj11E/CLyqYh8Hj3uW6OvDxSRT6LH/byItG/5rUOEiLhF5DMR\n+Xf0ebIc93oR+VJElonI4uhrHfK37ojQFxE3cD8wERgCXCoiQ7q2VJ3mcWBCs9duBN4xxgwC3ok+\nd5oQ8GtjzNHAicDPov+NnX7sdcAZxphjgJHABBE5EbgTuCd63KXA1V1Yxs50PfBVk+fJctwApxtj\nRjbpqtkhf+uOCH1gDFBojFlnjKkHngMmdXGZOoUx5j1gV7OXJwFPRB8/AUw+oIU6AIwxW4wxS6OP\nK7FB0BeHH7uxqqJPvdGbAc4AZkZfd9xxA4hIPnAO8Ej0uZAEx92KDvlbd0ro9wU2NXleFH0tWfQ0\nxmwBG45Ajy4uT6cSkQHAscAnJMGxR6s4lgHbgbeBtUCZMSYU3cWpf+/3Ar8BGlYWzyU5jhvsiX2u\niCwRkenR1zrkb90pa+TGWlRTuyU5kIikAy8BvzDGVCS6ePahzBgTBkaKSDfgFeDoWLsd2FJ1LhE5\nF9hujFkiImMbXo6xq6OOu4mTjTHFItIDeFtEVnXUBzvlSr8IKGjyPB8o7qKydIVtItIbIHq/vYvL\n0ylExIsN/H8ZY16OvpwUxw5gjCkDFmDbNLqJSMNFmxP/3k8GzheR9djq2jOwV/5OP24AjDHF0fvt\n2BP9GDrob90pob8IGBRt2fcB04BZXVymA2kWcEX08RXAa11Ylk4Rrc99FPjKGHN3k02OPnYRyYte\n4SMiAeA72PaMd4Ep0d0cd9zGmJuMMfnGmAHY/5/nG2O+i8OPG0BE0kQko+ExcBawnA76W3fM4CwR\nORt7JeAGZhhjbu/iInUKEXkWGIuddW8bcAvwKvAC0A/YCFxsjGne2HtIE5FTgPeBL9lTx/s7bL2+\nY49dREZgG+3c2Iu0F4wxt4nIYdgr4BzgM+ByY0xd15W080Srd24wxpybDMcdPcZXok89wDPGmNtF\nJJcO+Ft3TOgrpZRqm1Oqd5RSSiVAQ18ppZKIhr5SSiURDX2llEoiGvpKKZVENPSVUiqJaOgrpVQS\n0dBXSqkk8v8Bpui6oV5qV4IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x219a5b8b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93788916,  0.93552285],\n",
       "       [ 0.93914825,  0.93692648],\n",
       "       [ 0.94026798,  0.9378199 ],\n",
       "       ..., \n",
       "       [ 0.93209893,  0.93168622],\n",
       "       [ 0.93264765,  0.93213564],\n",
       "       [ 0.93263286,  0.93212622]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(test_X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94437253,  0.94437253],\n",
       "       [ 0.94437253,  0.94437253],\n",
       "       [ 0.94437253,  0.94437253],\n",
       "       ..., \n",
       "       [ 0.93531692,  0.93531692],\n",
       "       [ 0.93531692,  0.93661058],\n",
       "       [ 0.93661058,  0.93790424]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.300003"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxT_in = test_scalers[0]\n",
    "maxT_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    '''\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "    '''\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col]*maxT_in - predicted[row, col]*maxT_in)**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987965910530138"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_forecasts(test_y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
