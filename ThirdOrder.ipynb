{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProcessingData:\n",
    "    \n",
    "    def __init__(self,filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            u = pickle._Unpickler(f)\n",
    "            u.encoding = 'latin1'\n",
    "            self.data = u.load()\n",
    "\n",
    "    def fix_data(self, interval):\n",
    "        \"\"\"Fixes up the data. Makes sure we count two stage as single stage actions, don't count float actions,\n",
    "        converts action duration and dt to floats, fill's nan's in action_duration and drops all datapoints which\n",
    "        don't have dt equal to interval.\n",
    "        :param data:\n",
    "        :param interval: float:minutes\"\"\"\n",
    "        def f(x):\n",
    "            if x == 0:\n",
    "                return 0\n",
    "            elif x == 2 or x == 5:\n",
    "                return 2\n",
    "            elif x ==1 or x == 3:\n",
    "                return 1\n",
    "\n",
    "        def h(x):\n",
    "            if x == 1:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        def c(x):\n",
    "            if x == 2:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        self.data[\"action\"] = self.data[\"action\"].map(f)\n",
    "        self.data['action_heating'] = self.data[\"action\"].map(h)\n",
    "        self.data['action_cooling'] = self.data['action'].map(c)\n",
    "\n",
    "        #print self.data.head()\n",
    "\n",
    "        return self.data, self.data[self.data[\"dt\"] == interval]\n",
    "    \n",
    "    def filter_data(self):\n",
    "        self.data = self.data.drop(['t_next', 'dt', 'action', 'previous_action', 'action_duration', \\\n",
    "                                    'zone_temperatureHVAC_Zone_Shelter_Corridor'], axis=1)\n",
    "        return self.data\n",
    "    \n",
    "    def drop_nan(self):\n",
    "        self.data = self.data.dropna()\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = ProcessingData(\"../Data/avenal-animal-shelter_training_data.pkl\")\n",
    "training_data = training.fix_data(5)\n",
    "training_data = training.filter_data()\n",
    "training_data = training.drop_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = ProcessingData(\"../Data/avenal-animal-shelter_test_data.pkl\")\n",
    "testing_data = testing.fix_data(5)\n",
    "testing_data = testing.filter_data()\n",
    "testing_data = testing.drop_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaling(data):\n",
    "    scaled = np.empty([data.shape[0], data.shape[1]])\n",
    "    numSamples = data.shape[0]\n",
    "    numFeatures = data.shape[1]\n",
    "    dataValues = data.values\n",
    "    dataValues = dataValues.astype('float32')\n",
    "    for i in range(numFeatures):\n",
    "        maxNum = max(dataValues[:,i])\n",
    "        for j in range(numSamples):\n",
    "            scaled[j,i] = dataValues[j,i]/maxNum\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "    data: Sequence of observations as a list or NumPy array.\n",
    "    n_in: Number of lag observations as input (X).\n",
    "    n_out: Number of observations as output (y).\n",
    "    dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "    Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.85676116  0.63942021  0.          0.          0.        ]\n",
      " [ 0.85696673  0.63942021  0.          0.          0.        ]\n",
      " [ 0.85696673  0.63962066  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.85080147  0.74038088  0.          0.          0.        ]\n",
      " [ 0.85573369  0.74038088  0.          0.          0.        ]\n",
      " [ 0.85819978  0.74038088  0.          0.          0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.856761</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.641625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.641625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var1(t-2)  \\\n",
       "3   0.856761   0.639420        0.0        0.0        0.0   0.856967   \n",
       "4   0.856967   0.639420        0.0        0.0        0.0   0.856967   \n",
       "5   0.856967   0.639621        0.0        0.0        0.0   0.856967   \n",
       "6   0.856967   0.640222        0.0        0.0        0.0   0.855734   \n",
       "7   0.855734   0.641024        0.0        0.0        0.0   0.856967   \n",
       "\n",
       "   var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  var2(t-1)  \\\n",
       "3   0.639420        0.0        0.0        0.0   0.856967   0.639621   \n",
       "4   0.639621        0.0        0.0        0.0   0.856967   0.640222   \n",
       "5   0.640222        0.0        0.0        0.0   0.855734   0.641024   \n",
       "6   0.641024        0.0        0.0        0.0   0.856967   0.641625   \n",
       "7   0.641625        0.0        0.0        0.0   0.855734   0.641826   \n",
       "\n",
       "   var3(t-1)  var4(t-1)  var5(t-1)   var1(t)  \n",
       "3        0.0        0.0        0.0  0.856967  \n",
       "4        0.0        0.0        0.0  0.855734  \n",
       "5        0.0        0.0        0.0  0.856967  \n",
       "6        0.0        0.0        0.0  0.855734  \n",
       "7        0.0        0.0        0.0  0.856967  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled = scaling(training_data)\n",
    "print(train_scaled)\n",
    "train_reframed = series_to_supervised(train_scaled, 3, 1)\n",
    "train_reframed.drop(train_reframed.columns[-4:], axis=1, inplace=True)\n",
    "train_reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.747789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.748107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.748107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.747249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var1(t-2)  \\\n",
       "3   0.941785   0.747789        0.0        0.0        0.0   0.941785   \n",
       "4   0.941785   0.748107        0.0        0.0        0.0   0.944373   \n",
       "5   0.944373   0.748422        0.0        0.0        0.0   0.944373   \n",
       "6   0.944373   0.748731        0.0        0.0        0.0   0.944373   \n",
       "7   0.944373   0.749038        0.0        0.0        0.0   0.944373   \n",
       "\n",
       "   var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  var2(t-1)  \\\n",
       "3   0.748107        0.0        0.0        0.0   0.944373   0.748422   \n",
       "4   0.748422        0.0        0.0        0.0   0.944373   0.748731   \n",
       "5   0.748731        0.0        0.0        0.0   0.944373   0.749038   \n",
       "6   0.749038        0.0        0.0        0.0   0.944373   0.748744   \n",
       "7   0.748744        0.0        0.0        0.0   0.944373   0.747249   \n",
       "\n",
       "   var3(t-1)  var4(t-1)  var5(t-1)   var1(t)  \n",
       "3        0.0        0.0        0.0  0.944373  \n",
       "4        0.0        0.0        0.0  0.944373  \n",
       "5        0.0        0.0        0.0  0.944373  \n",
       "6        0.0        0.0        0.0  0.944373  \n",
       "7        0.0        0.0        0.0  0.944373  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled = scaling(testing_data)\n",
    "test_reframed = series_to_supervised(test_scaled, 3, 1)\n",
    "test_reframed.drop(test_reframed.columns[-4:], axis=1, inplace=True)\n",
    "test_reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53183, 3, 5) (53183,) (13387, 3, 5) (13387,)\n"
     ]
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "train = train_reframed.values\n",
    "test = test_reframed.values\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 3, 5))\n",
    "test_X = test_X.reshape((test_X.shape[0], 3, 5))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53183 samples, validate on 13387 samples\n",
      "Epoch 1/60\n",
      " - 6s - loss: 0.0556 - acc: 3.3845e-04 - val_loss: 0.0266 - val_acc: 7.4699e-04\n",
      "Epoch 2/60\n",
      " - 3s - loss: 0.0155 - acc: 3.3845e-04 - val_loss: 0.0341 - val_acc: 7.4699e-04\n",
      "Epoch 3/60\n",
      " - 2s - loss: 0.0156 - acc: 3.3845e-04 - val_loss: 0.0327 - val_acc: 7.4699e-04\n",
      "Epoch 4/60\n",
      " - 3s - loss: 0.0144 - acc: 3.3845e-04 - val_loss: 0.0314 - val_acc: 7.4699e-04\n",
      "Epoch 5/60\n",
      " - 4s - loss: 0.0149 - acc: 3.3845e-04 - val_loss: 0.0281 - val_acc: 7.4699e-04\n",
      "Epoch 6/60\n",
      " - 4s - loss: 0.0148 - acc: 3.3845e-04 - val_loss: 0.0273 - val_acc: 7.4699e-04\n",
      "Epoch 7/60\n",
      " - 2s - loss: 0.0146 - acc: 3.3845e-04 - val_loss: 0.0274 - val_acc: 7.4699e-04\n",
      "Epoch 8/60\n",
      " - 4s - loss: 0.0143 - acc: 3.3845e-04 - val_loss: 0.0268 - val_acc: 7.4699e-04\n",
      "Epoch 9/60\n",
      " - 5s - loss: 0.0143 - acc: 3.3845e-04 - val_loss: 0.0283 - val_acc: 7.4699e-04\n",
      "Epoch 10/60\n",
      " - 3s - loss: 0.0139 - acc: 3.3845e-04 - val_loss: 0.0313 - val_acc: 7.4699e-04\n",
      "Epoch 11/60\n",
      " - 3s - loss: 0.0138 - acc: 3.3845e-04 - val_loss: 0.0254 - val_acc: 7.4699e-04\n",
      "Epoch 12/60\n",
      " - 3s - loss: 0.0134 - acc: 3.3845e-04 - val_loss: 0.0256 - val_acc: 7.4699e-04\n",
      "Epoch 13/60\n",
      " - 3s - loss: 0.0134 - acc: 3.3845e-04 - val_loss: 0.0276 - val_acc: 7.4699e-04\n",
      "Epoch 14/60\n",
      " - 3s - loss: 0.0133 - acc: 3.3845e-04 - val_loss: 0.0278 - val_acc: 7.4699e-04\n",
      "Epoch 15/60\n",
      " - 3s - loss: 0.0130 - acc: 3.3845e-04 - val_loss: 0.0245 - val_acc: 7.4699e-04\n",
      "Epoch 16/60\n",
      " - 3s - loss: 0.0126 - acc: 3.3845e-04 - val_loss: 0.0271 - val_acc: 7.4699e-04\n",
      "Epoch 17/60\n",
      " - 4s - loss: 0.0127 - acc: 3.3845e-04 - val_loss: 0.0271 - val_acc: 7.4699e-04\n",
      "Epoch 18/60\n",
      " - 3s - loss: 0.0124 - acc: 3.3845e-04 - val_loss: 0.0232 - val_acc: 7.4699e-04\n",
      "Epoch 19/60\n",
      " - 3s - loss: 0.0121 - acc: 3.3845e-04 - val_loss: 0.0222 - val_acc: 7.4699e-04\n",
      "Epoch 20/60\n",
      " - 3s - loss: 0.0119 - acc: 3.3845e-04 - val_loss: 0.0221 - val_acc: 7.4699e-04\n",
      "Epoch 21/60\n",
      " - 4s - loss: 0.0118 - acc: 3.3845e-04 - val_loss: 0.0252 - val_acc: 7.4699e-04\n",
      "Epoch 22/60\n",
      " - 3s - loss: 0.0117 - acc: 3.3845e-04 - val_loss: 0.0259 - val_acc: 7.4699e-04\n",
      "Epoch 23/60\n",
      " - 6s - loss: 0.0117 - acc: 3.3845e-04 - val_loss: 0.0203 - val_acc: 7.4699e-04\n",
      "Epoch 24/60\n",
      " - 3s - loss: 0.0115 - acc: 3.3845e-04 - val_loss: 0.0197 - val_acc: 7.4699e-04\n",
      "Epoch 25/60\n",
      " - 4s - loss: 0.0112 - acc: 3.3845e-04 - val_loss: 0.0236 - val_acc: 7.4699e-04\n",
      "Epoch 26/60\n",
      " - 4s - loss: 0.0109 - acc: 3.3845e-04 - val_loss: 0.0234 - val_acc: 7.4699e-04\n",
      "Epoch 27/60\n",
      " - 4s - loss: 0.0109 - acc: 3.3845e-04 - val_loss: 0.0238 - val_acc: 7.4699e-04\n",
      "Epoch 28/60\n",
      " - 3s - loss: 0.0108 - acc: 3.3845e-04 - val_loss: 0.0233 - val_acc: 7.4699e-04\n",
      "Epoch 29/60\n",
      " - 3s - loss: 0.0105 - acc: 3.3845e-04 - val_loss: 0.0228 - val_acc: 7.4699e-04\n",
      "Epoch 30/60\n",
      " - 3s - loss: 0.0104 - acc: 3.3845e-04 - val_loss: 0.0223 - val_acc: 7.4699e-04\n",
      "Epoch 31/60\n",
      " - 3s - loss: 0.0100 - acc: 3.3845e-04 - val_loss: 0.0191 - val_acc: 7.4699e-04\n",
      "Epoch 32/60\n",
      " - 4s - loss: 0.0092 - acc: 3.3845e-04 - val_loss: 0.0224 - val_acc: 7.4699e-04\n",
      "Epoch 33/60\n",
      " - 4s - loss: 0.0094 - acc: 3.3845e-04 - val_loss: 0.0162 - val_acc: 7.4699e-04\n",
      "Epoch 34/60\n",
      " - 5s - loss: 0.0085 - acc: 3.3845e-04 - val_loss: 0.0176 - val_acc: 7.4699e-04\n",
      "Epoch 35/60\n",
      " - 4s - loss: 0.0086 - acc: 3.3845e-04 - val_loss: 0.0151 - val_acc: 7.4699e-04\n",
      "Epoch 36/60\n",
      " - 4s - loss: 0.0079 - acc: 3.3845e-04 - val_loss: 0.0146 - val_acc: 7.4699e-04\n",
      "Epoch 37/60\n",
      " - 4s - loss: 0.0073 - acc: 3.3845e-04 - val_loss: 0.0126 - val_acc: 7.4699e-04\n",
      "Epoch 38/60\n",
      " - 4s - loss: 0.0070 - acc: 3.3845e-04 - val_loss: 0.0127 - val_acc: 7.4699e-04\n",
      "Epoch 39/60\n",
      " - 4s - loss: 0.0060 - acc: 3.3845e-04 - val_loss: 0.0091 - val_acc: 7.4699e-04\n",
      "Epoch 40/60\n",
      " - 5s - loss: 0.0063 - acc: 3.3845e-04 - val_loss: 0.0121 - val_acc: 7.4699e-04\n",
      "Epoch 41/60\n",
      " - 6s - loss: 0.0057 - acc: 3.3845e-04 - val_loss: 0.0083 - val_acc: 7.4699e-04\n",
      "Epoch 42/60\n",
      " - 4s - loss: 0.0049 - acc: 3.3845e-04 - val_loss: 0.0086 - val_acc: 7.4699e-04\n",
      "Epoch 43/60\n",
      " - 3s - loss: 0.0044 - acc: 3.3845e-04 - val_loss: 0.0074 - val_acc: 7.4699e-04\n",
      "Epoch 44/60\n",
      " - 4s - loss: 0.0041 - acc: 3.3845e-04 - val_loss: 0.0072 - val_acc: 7.4699e-04\n",
      "Epoch 45/60\n",
      " - 4s - loss: 0.0042 - acc: 3.3845e-04 - val_loss: 0.0072 - val_acc: 7.4699e-04\n",
      "Epoch 46/60\n",
      " - 4s - loss: 0.0038 - acc: 3.3845e-04 - val_loss: 0.0071 - val_acc: 7.4699e-04\n",
      "Epoch 47/60\n",
      " - 4s - loss: 0.0038 - acc: 3.3845e-04 - val_loss: 0.0065 - val_acc: 7.4699e-04\n",
      "Epoch 48/60\n",
      " - 3s - loss: 0.0035 - acc: 3.3845e-04 - val_loss: 0.0069 - val_acc: 7.4699e-04\n",
      "Epoch 49/60\n",
      " - 3s - loss: 0.0033 - acc: 3.3845e-04 - val_loss: 0.0067 - val_acc: 7.4699e-04\n",
      "Epoch 50/60\n",
      " - 3s - loss: 0.0032 - acc: 3.3845e-04 - val_loss: 0.0056 - val_acc: 7.4699e-04\n",
      "Epoch 51/60\n",
      " - 3s - loss: 0.0032 - acc: 3.3845e-04 - val_loss: 0.0062 - val_acc: 7.4699e-04\n",
      "Epoch 52/60\n",
      " - 3s - loss: 0.0033 - acc: 3.3845e-04 - val_loss: 0.0047 - val_acc: 7.4699e-04\n",
      "Epoch 53/60\n",
      " - 3s - loss: 0.0031 - acc: 3.3845e-04 - val_loss: 0.0057 - val_acc: 7.4699e-04\n",
      "Epoch 54/60\n",
      " - 3s - loss: 0.0030 - acc: 3.3845e-04 - val_loss: 0.0044 - val_acc: 7.4699e-04\n",
      "Epoch 55/60\n",
      " - 3s - loss: 0.0032 - acc: 3.3845e-04 - val_loss: 0.0051 - val_acc: 7.4699e-04\n",
      "Epoch 56/60\n",
      " - 3s - loss: 0.0030 - acc: 3.3845e-04 - val_loss: 0.0054 - val_acc: 7.4699e-04\n",
      "Epoch 57/60\n",
      " - 3s - loss: 0.0027 - acc: 3.3845e-04 - val_loss: 0.0052 - val_acc: 7.4699e-04\n",
      "Epoch 58/60\n",
      " - 3s - loss: 0.0030 - acc: 3.3845e-04 - val_loss: 0.0045 - val_acc: 7.4699e-04\n",
      "Epoch 59/60\n",
      " - 3s - loss: 0.0027 - acc: 3.3845e-04 - val_loss: 0.0053 - val_acc: 7.4699e-04\n",
      "Epoch 60/60\n",
      " - 3s - loss: 0.0028 - acc: 3.3845e-04 - val_loss: 0.0044 - val_acc: 7.4699e-04\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(15, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=60, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqh/RoK+UUv3I/wPVTHF5CeOwUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2561e7424a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9384973 ],\n",
       "       [ 0.93922067],\n",
       "       [ 0.93975675],\n",
       "       ..., \n",
       "       [ 0.93290091],\n",
       "       [ 0.93315172],\n",
       "       [ 0.93369222]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(test_X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.299999999999997"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxT_in = max(testing_data['t_in'])\n",
    "maxT_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72.54584503,  72.60176086,  72.64319611, ...,  72.1132431 ,\n",
       "        72.13262939,  72.17440796])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat = np.array([])\n",
    "for y in yhat:\n",
    "    inv_yhat = np.append(inv_yhat, y*maxT_in)\n",
    "inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72.99999694,  72.99999694,  72.99999694, ...,  72.29999794,\n",
       "        72.39999779,  72.49999765])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_y = np.array([])\n",
    "for y in test_y:\n",
    "    inv_y = np.append(inv_y, y*maxT_in)\n",
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.856\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
