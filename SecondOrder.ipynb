{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProcessingData:\n",
    "    \n",
    "    def __init__(self,filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            u = pickle._Unpickler(f)\n",
    "            u.encoding = 'latin1'\n",
    "            self.data = u.load()\n",
    "\n",
    "    def fix_data(self, interval):\n",
    "        \"\"\"Fixes up the data. Makes sure we count two stage as single stage actions, don't count float actions,\n",
    "        converts action duration and dt to floats, fill's nan's in action_duration and drops all datapoints which\n",
    "        don't have dt equal to interval.\n",
    "        :param data:\n",
    "        :param interval: float:minutes\"\"\"\n",
    "        def f(x):\n",
    "            if x == 0:\n",
    "                return 0\n",
    "            elif x == 2 or x == 5:\n",
    "                return 2\n",
    "            elif x ==1 or x == 3:\n",
    "                return 1\n",
    "\n",
    "        def h(x):\n",
    "            if x == 1:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        def c(x):\n",
    "            if x == 2:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        self.data[\"action\"] = self.data[\"action\"].map(f)\n",
    "        self.data['action_heating'] = self.data[\"action\"].map(h)\n",
    "        self.data['action_cooling'] = self.data['action'].map(c)\n",
    "\n",
    "        #print self.data.head()\n",
    "\n",
    "        return self.data, self.data[self.data[\"dt\"] == interval]\n",
    "    \n",
    "    def filter_data(self):\n",
    "        self.data = self.data.drop(['t_next', 'dt', 'action', 'previous_action', 'action_duration', \\\n",
    "                                    'zone_temperatureHVAC_Zone_Shelter_Corridor'], axis=1)\n",
    "        return self.data\n",
    "    \n",
    "    def drop_nan(self):\n",
    "        self.data = self.data.dropna()\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = ProcessingData(\"../Data/avenal-animal-shelter_training_data.pkl\")\n",
    "training_data = training.fix_data(5)\n",
    "training_data = training.filter_data()\n",
    "training_data = training.drop_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = ProcessingData(\"../Data/avenal-animal-shelter_test_data.pkl\")\n",
    "testing_data = testing.fix_data(5)\n",
    "testing_data = testing.filter_data()\n",
    "testing_data = testing.drop_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaling(data):\n",
    "    scaled = np.empty([data.shape[0], data.shape[1]])\n",
    "    numSamples = data.shape[0]\n",
    "    numFeatures = data.shape[1]\n",
    "    dataValues = data.values\n",
    "    dataValues = dataValues.astype('float32')\n",
    "    for i in range(numFeatures):\n",
    "        maxNum = max(dataValues[:,i])\n",
    "        for j in range(numSamples):\n",
    "            scaled[j,i] = dataValues[j,i]/maxNum\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "    data: Sequence of observations as a list or NumPy array.\n",
    "    n_in: Number of lag observations as input (X).\n",
    "    n_out: Number of observations as output (y).\n",
    "    dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "    Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.85676116  0.63942021  0.          0.          0.        ]\n",
      " [ 0.85696673  0.63942021  0.          0.          0.        ]\n",
      " [ 0.85696673  0.63962066  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.85080147  0.74038088  0.          0.          0.        ]\n",
      " [ 0.85573369  0.74038088  0.          0.          0.        ]\n",
      " [ 0.85819978  0.74038088  0.          0.          0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.856761</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.639621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.640222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.641625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  \\\n",
       "2   0.856761   0.639420        0.0        0.0        0.0   0.856967   \n",
       "3   0.856967   0.639420        0.0        0.0        0.0   0.856967   \n",
       "4   0.856967   0.639621        0.0        0.0        0.0   0.856967   \n",
       "5   0.856967   0.640222        0.0        0.0        0.0   0.855734   \n",
       "6   0.855734   0.641024        0.0        0.0        0.0   0.856967   \n",
       "\n",
       "   var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)  \n",
       "2   0.639420        0.0        0.0        0.0  0.856967  \n",
       "3   0.639621        0.0        0.0        0.0  0.856967  \n",
       "4   0.640222        0.0        0.0        0.0  0.855734  \n",
       "5   0.641024        0.0        0.0        0.0  0.856967  \n",
       "6   0.641625        0.0        0.0        0.0  0.855734  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled = scaling(training_data)\n",
    "print(train_scaled)\n",
    "train_reframed = series_to_supervised(train_scaled, 2, 1)\n",
    "train_reframed.drop(train_reframed.columns[-4:], axis=1, inplace=True)\n",
    "train_reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.747789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.748107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941785</td>\n",
       "      <td>0.748107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  \\\n",
       "2   0.941785   0.747789        0.0        0.0        0.0   0.941785   \n",
       "3   0.941785   0.748107        0.0        0.0        0.0   0.944373   \n",
       "4   0.944373   0.748422        0.0        0.0        0.0   0.944373   \n",
       "5   0.944373   0.748731        0.0        0.0        0.0   0.944373   \n",
       "6   0.944373   0.749038        0.0        0.0        0.0   0.944373   \n",
       "\n",
       "   var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)  \n",
       "2   0.748107        0.0        0.0        0.0  0.944373  \n",
       "3   0.748422        0.0        0.0        0.0  0.944373  \n",
       "4   0.748731        0.0        0.0        0.0  0.944373  \n",
       "5   0.749038        0.0        0.0        0.0  0.944373  \n",
       "6   0.748744        0.0        0.0        0.0  0.944373  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled = scaling(testing_data)\n",
    "test_reframed = series_to_supervised(test_scaled, 2, 1)\n",
    "test_reframed.drop(test_reframed.columns[-4:], axis=1, inplace=True)\n",
    "test_reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53184, 2, 5) (53184,) (13388, 2, 5) (13388,)\n"
     ]
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "train = train_reframed.values\n",
    "test = test_reframed.values\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 2, 5))\n",
    "test_X = test_X.reshape((test_X.shape[0], 2, 5))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53184 samples, validate on 13388 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.1069 - acc: 3.3845e-04 - val_loss: 0.0318 - val_acc: 7.4694e-04\n",
      "Epoch 2/50\n",
      " - 3s - loss: 0.0177 - acc: 3.3845e-04 - val_loss: 0.0367 - val_acc: 7.4694e-04\n",
      "Epoch 3/50\n",
      " - 3s - loss: 0.0169 - acc: 3.3845e-04 - val_loss: 0.0367 - val_acc: 7.4694e-04\n",
      "Epoch 4/50\n",
      " - 3s - loss: 0.0165 - acc: 3.3845e-04 - val_loss: 0.0367 - val_acc: 7.4694e-04\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.0160 - acc: 3.3845e-04 - val_loss: 0.0357 - val_acc: 7.4694e-04\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.0158 - acc: 3.3845e-04 - val_loss: 0.0355 - val_acc: 7.4694e-04\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.0156 - acc: 3.3845e-04 - val_loss: 0.0357 - val_acc: 7.4694e-04\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.0153 - acc: 3.3845e-04 - val_loss: 0.0345 - val_acc: 7.4694e-04\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.0151 - acc: 3.3845e-04 - val_loss: 0.0347 - val_acc: 7.4694e-04\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.0149 - acc: 3.3845e-04 - val_loss: 0.0334 - val_acc: 7.4694e-04\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.0147 - acc: 3.3845e-04 - val_loss: 0.0341 - val_acc: 7.4694e-04\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.0144 - acc: 3.3845e-04 - val_loss: 0.0334 - val_acc: 7.4694e-04\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.0142 - acc: 3.3845e-04 - val_loss: 0.0327 - val_acc: 7.4694e-04\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.0139 - acc: 3.3845e-04 - val_loss: 0.0314 - val_acc: 7.4694e-04\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.0135 - acc: 3.3845e-04 - val_loss: 0.0318 - val_acc: 7.4694e-04\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.0135 - acc: 3.3845e-04 - val_loss: 0.0319 - val_acc: 7.4694e-04\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.0133 - acc: 3.3845e-04 - val_loss: 0.0317 - val_acc: 7.4694e-04\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.0131 - acc: 3.3845e-04 - val_loss: 0.0314 - val_acc: 7.4694e-04\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.0129 - acc: 3.3845e-04 - val_loss: 0.0304 - val_acc: 7.4694e-04\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.0126 - acc: 3.3845e-04 - val_loss: 0.0281 - val_acc: 7.4694e-04\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.0124 - acc: 3.3845e-04 - val_loss: 0.0266 - val_acc: 7.4694e-04\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.0122 - acc: 3.3845e-04 - val_loss: 0.0268 - val_acc: 7.4694e-04\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.0119 - acc: 3.3845e-04 - val_loss: 0.0276 - val_acc: 7.4694e-04\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.0116 - acc: 3.3845e-04 - val_loss: 0.0236 - val_acc: 7.4694e-04\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.0114 - acc: 3.3845e-04 - val_loss: 0.0236 - val_acc: 7.4694e-04\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.0112 - acc: 3.3845e-04 - val_loss: 0.0241 - val_acc: 7.4694e-04\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.0109 - acc: 3.3845e-04 - val_loss: 0.0242 - val_acc: 7.4694e-04\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.0104 - acc: 3.3845e-04 - val_loss: 0.0237 - val_acc: 7.4694e-04\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.0102 - acc: 3.3845e-04 - val_loss: 0.0230 - val_acc: 7.4694e-04\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.0096 - acc: 3.3845e-04 - val_loss: 0.0220 - val_acc: 7.4694e-04\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.0096 - acc: 3.3845e-04 - val_loss: 0.0220 - val_acc: 7.4694e-04\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.0093 - acc: 3.3845e-04 - val_loss: 0.0211 - val_acc: 7.4694e-04\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.0085 - acc: 3.3845e-04 - val_loss: 0.0170 - val_acc: 7.4694e-04\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.0086 - acc: 3.3845e-04 - val_loss: 0.0214 - val_acc: 7.4694e-04\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.0075 - acc: 3.3845e-04 - val_loss: 0.0215 - val_acc: 7.4694e-04\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.0071 - acc: 3.3845e-04 - val_loss: 0.0159 - val_acc: 7.4694e-04\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.0068 - acc: 3.3845e-04 - val_loss: 0.0117 - val_acc: 7.4694e-04\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.0063 - acc: 3.3845e-04 - val_loss: 0.0121 - val_acc: 7.4694e-04\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.0061 - acc: 3.3845e-04 - val_loss: 0.0124 - val_acc: 7.4694e-04\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.0049 - acc: 3.3845e-04 - val_loss: 0.0079 - val_acc: 7.4694e-04\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.0041 - acc: 3.3845e-04 - val_loss: 0.0082 - val_acc: 7.4694e-04\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.0038 - acc: 3.3845e-04 - val_loss: 0.0068 - val_acc: 7.4694e-04\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.0032 - acc: 3.3845e-04 - val_loss: 0.0040 - val_acc: 7.4694e-04\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.0030 - acc: 3.3845e-04 - val_loss: 0.0056 - val_acc: 7.4694e-04\n",
      "Epoch 45/50\n",
      " - 2s - loss: 0.0025 - acc: 3.3845e-04 - val_loss: 0.0040 - val_acc: 7.4694e-04\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.0027 - acc: 3.3845e-04 - val_loss: 0.0037 - val_acc: 7.4694e-04\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.0025 - acc: 3.3845e-04 - val_loss: 0.0038 - val_acc: 7.4694e-04\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.0028 - acc: 3.3845e-04 - val_loss: 0.0040 - val_acc: 7.4694e-04\n",
      "Epoch 49/50\n",
      " - 2s - loss: 0.0026 - acc: 3.3845e-04 - val_loss: 0.0047 - val_acc: 7.4694e-04\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.0026 - acc: 3.3845e-04 - val_loss: 0.0031 - val_acc: 7.4694e-04\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19f6283c860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93884981],\n",
       "       [ 0.94013101],\n",
       "       [ 0.94124991],\n",
       "       ..., \n",
       "       [ 0.93499261],\n",
       "       [ 0.93499386],\n",
       "       [ 0.93562043]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(test_X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.299999999999997"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxT_in = max(testing_data['t_in'])\n",
    "maxT_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72.5730896 ,  72.67212677,  72.75862122, ...,  72.27493286,\n",
       "        72.27503204,  72.32346344])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat = np.array([])\n",
    "for y in yhat:\n",
    "    inv_yhat = np.append(inv_yhat, y*maxT_in)\n",
    "inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72.99999694,  72.99999694,  72.99999694, ...,  72.29999794,\n",
       "        72.39999779,  72.49999765])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_y = np.array([])\n",
    "for y in test_y:\n",
    "    inv_y = np.append(inv_y, y*maxT_in)\n",
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.770\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
